{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3610jvsc74a57bd0eb5e09632d6ea1cbf3eb9da7e37b7cf581db5ed13074b21cc44e159dc62acdab",
   "display_name": "Python 3.6.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Standard flow control and data processing DataPipes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterDataPipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example IterDataPipe\n",
    "class ExampleIterPipe(IterDataPipe):\n",
    "    def __init__(self, range = 20):\n",
    "        self.range = range\n",
    "    def __iter__(self):\n",
    "        for i in range(self.range):\n",
    "            yield i"
   ]
  },
  {
   "source": [
    "## Concat\n",
    "\n",
    "Function: `concat`\n",
    "\n",
    "Description: Returns DataPipes with elements from the first datapipe following by elements from second datapipes\n",
    "\n",
    "Alternatives:\n",
    "\n",
    "    `dp = dp + dp2`\n",
    "    \n",
    "    `dp = dp.concat(dp2, dp3)`\n",
    "\n",
    "Example:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n1\n2\n3\n0\n1\n2\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(4)\n",
    "dp2 = ExampleIterPipe(3)\n",
    "dp = dp.concat(dp2)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## Batch\n",
    "\n",
    "Function: `batch`\n",
    "\n",
    "Description: \n",
    "\n",
    "Alternatives:\n",
    "\n",
    "Arguments:\n",
    "  - `batch_size: int` desired batch size\n",
    "  - `batch_level: bool = False` whether elements from the source DataPipe counted as independant objects or we count mini-batched elements indivudually.\n",
    "  - `drop_last: bool = False`\n",
    "\n",
    "Example:\n",
    "\n",
    "Classic batching produce partial batches by default\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2]\n[3, 4, 5]\n[6, 7, 8]\n[9]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "To drop incomplete batches add `drop_last` argument"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2]\n[3, 4, 5]\n[6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3, drop_last=True)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "Without `batch_level` override sequential `batch` calls do rebatching."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1]\n[2, 3]\n[4, 5]\n[6, 7]\n[8, 9]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).batch(2)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "Setting `batch_level=True` allows to take input lists as singular objects and nest them"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0, 1, 2], [3, 4, 5]]\n[[6, 7, 8], [9]]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).batch(2, batch_level=True)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## Map\n",
    "\n",
    "Function: `map`\n",
    "\n",
    "Description: \n",
    "\n",
    "Alternatives:\n",
    "\n",
    "Arguments:\n",
    "  - `batch_level: bool = False` whether elements from the source DataPipe counted as independant objects or we process mini-batched elements as whole.\n",
    " \n",
    "Example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n2\n4\n6\n8\n10\n12\n14\n16\n18\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).map(lambda x: x * 2)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "Classic `map` applies function to every element inside mini-batches by default\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 2, 4]\n[6, 8, 10]\n[12, 14, 16]\n[18]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).map(lambda x: x * 2)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "To apply function on entire mini-batch use `batch_level` argument"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2, 0, 1, 2]\n[3, 4, 5, 3, 4, 5]\n[6, 7, 8, 6, 7, 8]\n[9, 9]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).map(lambda x: x * 2, batch_level=True)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## Filter\n",
    "\n",
    "Function: `filter`\n",
    "\n",
    "Description: \n",
    "\n",
    "Alternatives:\n",
    "\n",
    "Arguments:\n",
    "  - `batch_level: bool = False` whether elements from the source DataPipe counted as independant objects or we process mini-batched elements as whole.\n",
    "  - `drop_empty_batches = True` whether empty many batches dropped or not.\n",
    " \n",
    "Example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n2\n4\n6\n8\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).filter(lambda x: x % 2 == 0)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "Classic `filter` applies filter function to every element inside mini-batches by default\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 2]\n[4]\n[6, 8]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10)\n",
    "dp = dp.batch(3).filter(lambda x: x % 2 == 0)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "By default if mini-batch ends with zero elements after filtering it is dropped from response"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[5]\n[6, 7, 8]\n[9]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10)\n",
    "dp = dp.batch(3).filter(lambda x: x > 4)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "You can override this behaviour using `drop_empty_batches` argument"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n[5]\n[6, 7, 8]\n[9]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10)\n",
    "dp = dp.batch(3).filter(lambda x: x > 4, drop_empty_batches=False)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "You can also apply filtering function on top of entire mini-batch using `batch_level` agrument"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10)\n",
    "dp = dp.batch(3).filter(lambda l: len(l) < 3, batch_level=True)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## Shuffle\n",
    "\n",
    "Function: `shuffle`\n",
    "\n",
    "Description: \n",
    "\n",
    "Alternatives:\n",
    "\n",
    "Arguments:\n",
    "  - `batch_level: bool = False` whether elements from the source DataPipe counted as independant objects or we process mini-batched elements as whole.\n",
    "  - `buffer_size: int = 10000`\n",
    "  - `cross_shuffle: bool = True`\n",
    " \n",
    "Example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6\n4\n2\n0\n9\n7\n5\n3\n1\n8\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).shuffle()\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "By default `shuffle` shuffles items inside of mini-batches across all input batches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 4, 1]\n[9, 7, 8]\n[2, 6, 5]\n[3]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).shuffle()\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "To shuffle items inside of mini-batches only, without passing mini-batch borders use `cross_shuffle` argument"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 2]\n[5, 3, 4]\n[8, 7, 6]\n[9]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).shuffle(cross_shuffle = False)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "To shuffle items on mini-batch level (without changing internal order of items inside mini-batches) use `batch_level` argument"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[3, 4, 5]\n[9]\n[0, 1, 2]\n[6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).shuffle(batch_level = True)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## Unbatch\n",
    "\n",
    "Function: `unbatch`\n",
    "\n",
    "Description: \n",
    "\n",
    "Alternatives:\n",
    "\n",
    "Arguments:\n",
    " \n",
    "Example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n9\n6\n5\n7\n8\n2\n3\n1\n0\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).shuffle().unbatch()\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## Collate\n",
    "\n",
    "Function: `collate`\n",
    "\n",
    "Description: \n",
    "\n",
    "Alternatives:\n",
    "\n",
    "Arguments:\n",
    " \n",
    "Example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([0, 1, 2])\ntensor([3, 4, 5])\ntensor([6, 7, 8])\ntensor([9])\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).collate()\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## GroupBy\n",
    "\n",
    "Function: `groupby`\n",
    "\n",
    "Usage: `dp.groupby(lambda x: x[0])`\n",
    "\n",
    "Description: Batching items by combining items with same key into same batch \n",
    "\n",
    "Arguments:\n",
    " - `group_key_fn`\n",
    " - `group_size` - yeild resulted group as soon as `group_size` elements accumulated\n",
    " - `guaranteed_group_size:int = None`\n",
    " - `batch_level`\n",
    "\n",
    "#### Attention\n",
    "As datasteam can be arbitrary large, grouping is done on best effort basis and there is no guarantee that same key will never present in the different groups."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 0), (0, 9), (0, 6), (0, 3)]\n[(1, 4), (1, 7), (1, 1)]\n[(2, 8), (2, 2), (2, 5)]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).map(lambda x: (x % 3, x)).shuffle().groupby(lambda x: x[0])\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "By default grouping is applied individually on each item of input mini-batches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(1, 4), (1, 1), (1, 10), (1, 7), (1, 13)]\n[(2, 2), (2, 5), (2, 8), (2, 14), (2, 11)]\n[(0, 12), (0, 9), (0, 0), (0, 6), (0, 3)]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(15).map(lambda x: (x % 3, x)).shuffle().groupby(lambda x: x[0])\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "Group key function gets entire mini-batch as input if `batch_level` is True"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n[[9]]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(10).batch(3).groupby(lambda x: len(x), batch_level = True)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "When internal buffer (defined by `buffer_size`) is overfilled, groupby will yield biggest group available"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(1, 10), (1, 1)]\n[(2, 5), (2, 2), (2, 8)]\n[(0, 6), (0, 3), (0, 0)]\n[(1, 13), (1, 7)]\n[(2, 14), (2, 11)]\n[(0, 9), (0, 12)]\n[(1, 4)]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(15).map(lambda x: (x % 3, x)).shuffle().groupby(lambda x: x[0], buffer_size = 5)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "`groupby` will produce `group_size` sized batches on as fast as possible basis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(1, 1), (1, 4), (1, 7)]\n[(2, 2), (2, 5), (2, 8)]\n[(0, 3), (0, 0), (0, 6)]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(9).map(lambda x: (x % 3, x)).shuffle().groupby(lambda x: x[0], group_size = 3)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "Remaining groups must be at least `guaranteed_group_size` big. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(1, 13), (1, 10), (1, 1)]\n[(0, 12), (0, 9), (0, 3)]\n[(2, 14), (2, 11), (2, 8)]\n[(0, 6), (0, 0)]\n[(1, 4), (1, 7)]\n[(2, 2), (2, 5)]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(15).map(lambda x: (x % 3, x)).shuffle().groupby(lambda x: x[0], group_size = 3, guaranteed_group_size = 2)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "Without defined `group_size` function will try to accumulate at least `guaranteed_group_size` elements before yielding resulted group"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 6), (0, 0), (0, 12), (0, 3), (0, 9)]\n[(2, 5), (2, 11), (2, 8), (2, 14), (2, 2)]\n[(1, 1), (1, 4), (1, 10), (1, 7), (1, 13)]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(15).map(lambda x: (x % 3, x)).shuffle().groupby(lambda x: x[0], guaranteed_group_size = 2)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "This behaviour becomes noticable when data is bigger than buffer and some groups getting evicted before gathering all potential items"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 0), (0, 3)]\n[(1, 1), (1, 4), (1, 7)]\n[(2, 2), (2, 5), (2, 8)]\n[(0, 6), (0, 9), (0, 12)]\n[(1, 10), (1, 13)]\n[(2, 11), (2, 14)]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(15).map(lambda x: (x % 3, x)).groupby(lambda x: x[0], guaranteed_group_size = 2, buffer_size = 6)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "With randomness involved you might end up with incomplete groups (so next example expected to fail in most cases)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(2, 8), (2, 2), (2, 14)]\n",
      "[(1, 7), (1, 13), (1, 1)]\n",
      "[(0, 9), (0, 12), (0, 6), (0, 3)]\n",
      "[(2, 11), (2, 5)]\n",
      "[(1, 10), (1, 4)]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "Exception",
     "evalue": "('Failed to group items', '[(0, 0)]')",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-086b86b43125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExampleIterPipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguaranteed_group_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dataset/pytorch/torch/utils/data/datapipes/iter/grouping.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguaranteed_group_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbiggest_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguaranteed_group_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_remaining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Failed to group items'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbiggest_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguaranteed_group_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbiggest_size\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguaranteed_group_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: ('Failed to group items', '[(0, 0)]')"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(15).map(lambda x: (x % 3, x)).shuffle().groupby(lambda x: x[0], guaranteed_group_size = 2, buffer_size = 6)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "To avoid this error and drop incomplete groups, use `drop_remaining` argument"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(2, 5), (2, 11), (2, 14), (2, 2)]\n",
      "[(1, 7), (1, 10), (1, 13), (1, 4), (1, 1)]\n",
      "[(0, 9), (0, 0), (0, 6), (0, 3), (0, 12)]\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(15).map(lambda x: (x % 3, x)).shuffle().groupby(lambda x: x[0], guaranteed_group_size = 2, buffer_size = 6, drop_remaining = True)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## Zip\n",
    "\n",
    "Function: `zip`\n",
    "\n",
    "Description: \n",
    "\n",
    "Alternatives:\n",
    "\n",
    "Arguments:\n",
    " \n",
    "Example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(0, 0)\n(1, 3)\n(2, 1)\n(3, 2)\n(4, 4)\n"
     ]
    }
   ],
   "source": [
    "_dp = ExampleIterPipe(5).shuffle()\n",
    "dp = ExampleIterPipe(5).zip(_dp)\n",
    "for i in dp:\n",
    "    print(i)"
   ]
  },
  {
   "source": [
    "## Fork\n",
    "\n",
    "Function: `fork`\n",
    "\n",
    "Description: \n",
    "\n",
    "Alternatives:\n",
    "\n",
    "Arguments:\n",
    " \n",
    "Example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n1\n0\n1\n0\n1\n"
     ]
    }
   ],
   "source": [
    "dp = ExampleIterPipe(2)\n",
    "dp1, dp2, dp3 = dp.fork(3)\n",
    "for i in dp1 + dp2 + dp3:\n",
    "    print(i)"
   ]
  }
 ]
}